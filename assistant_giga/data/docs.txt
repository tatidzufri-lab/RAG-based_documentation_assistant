Машинное обучение - это раздел искусственного интеллекта, который позволяет компьютерам обучаться на данных без явного программирования. Основные типы машинного обучения включают обучение с учителем, обучение без учителя и обучение с подкреплением. Обучение с учителем использует размеченные данные для предсказания результатов.

Нейронные сети - это модели машинного обучения, вдохновлённые структурой человеческого мозга. Они состоят из слоёв взаимосвязанных нейронов, которые обрабатывают информацию. Глубокие нейронные сети содержат множество скрытых слоёв и способны обучаться сложным паттернам. Они используются для распознавания изображений, обработки текста и многих других задач.

Обработка естественного языка (NLP) - это область, которая фокусируется на взаимодействии компьютеров и человеческого языка. NLP включает задачи такие как машинный перевод, анализ тональности, извлечение информации и генерация текста. Современные модели NLP основаны на архитектуре трансформеров и используют механизм внимания.

Трансформеры - это архитектура нейронных сетей, представленная в статье "Attention is All You Need" в 2017 году. Они используют механизм самовнимания для обработки последовательностей данных. Трансформеры стали основой для моделей типа BERT, GPT и T5. Они значительно превосходят предыдущие архитектуры в задачах NLP.

Векторные представления слов (embeddings) - это способ представления слов в виде плотных векторов фиксированной размерности. Word2Vec и GloVe были ранними методами создания embeddings. Современные модели создают контекстуальные embeddings, где представление слова зависит от контекста. Embeddings используются для измерения семантического сходства между словами и текстами.

RAG (Retrieval-Augmented Generation) - это подход, который комбинирует извлечение информации из базы знаний с генерацией текста языковыми моделями. RAG системы сначала находят релевантные документы, затем используют их как контекст для генерации ответа. Это позволяет моделям отвечать на вопросы на основе актуальной информации без дополнительного обучения.

Векторные базы данных - это специализированные системы хранения, оптимизированные для работы с векторными представлениями. Они поддерживают быстрый поиск ближайших соседей (nearest neighbor search). ChromaDB, Pinecone и Weaviate - примеры популярных векторных баз данных. Они используются в RAG системах, рекомендательных системах и поиске по семантическому сходству.

Prompt engineering - это практика разработки эффективных инструкций для языковых моделей. Качество промпта существенно влияет на качество ответа модели. Техники включают few-shot learning, chain-of-thought prompting и использование специальных форматов. Хороший промпт должен быть чётким, контекстуальным и структурированным.

Fine-tuning - это процесс дообучения предобученной модели на специфических данных для конкретной задачи. Fine-tuning позволяет адаптировать большие языковые модели под определённые домены или стили. Это требует меньше данных и вычислительных ресурсов, чем обучение с нуля. Parameter-efficient fine-tuning (PEFT) методы, такие как LoRA, делают этот процесс ещё более эффективным.

Оценка качества LLM - это важная задача при разработке AI систем. Метрики включают BLEU, ROUGE для генерации текста, точность для классификации. Для RAG систем используются специализированные метрики: faithfulness, answer relevance, context precision. Человеческая оценка остаётся золотым стандартом, но автоматические метрики позволяют быстро итерировать.

Кеширование в AI системах - это техника сохранения результатов вычислений для повторного использования. В RAG системах кеширование ответов на частые вопросы снижает затраты на API и уменьшает latency. Стратегии кеширования включают LRU (Least Recently Used), TTL (Time To Live) и семантическое кеширование. Важно учитывать актуальность закешированных данных.

Chunking стратегии - это методы разбиения длинных документов на управляемые фрагменты. Размер чанка влияет на качество поиска и контекста. Фиксированный размер (300-500 символов) прост в реализации. Семантический chunking разбивает текст по смысловым границам. Оверлэп между чанками помогает сохранить контекст на границах.

Температура в языковых моделях - это гиперпараметр, контролирующий случайность генерации. Низкая температура (0.1-0.3) делает ответы более детерминированными и сфокусированными. Высокая температура (0.8-1.0) увеличивает креативность и разнообразие. Для фактических вопросов в RAG обычно используют низкую температуру.

Token limits - это ограничения на количество токенов, которые может обработать модель за один запрос. GPT-4 поддерживает до 128K токенов в некоторых версиях. Важно учитывать, что лимит включает и промпт, и контекст, и ответ. Эффективное управление контекстом критично для работы с большими документами.

Semantic search - это поиск по смыслу, а не по точному совпадению ключевых слов. Использует векторные представления для измерения семантической близости. Работает лучше традиционного поиска для сложных запросов. Гибридный поиск комбинирует keyword search и semantic search для лучших результатов.

GigaChat - это российская языковая модель, разработанная Сбером. Она специализируется на русском языке и поддерживает различные задачи обработки текста. GigaChat предоставляет API для интеграции в приложения. Модель обучена на большом корпусе русскоязычных текстов и хорошо понимает контекст и нюансы русского языка.
